{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf40cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('apt install libdb5.3-dev')\n",
    "os.system('pip install gutenberg')\n",
    "os.system('pip install requests')\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240e583d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5504/2634228220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Author'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Link'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ID'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bookshelf'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Text'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "def remove_funny_tokens(text):\n",
    "    tokens = text.split()\n",
    "    sample = ' '.join(' '.join(tokens).replace('xe2x80x9c', ' ').replace('xe2x80x9d', ' ')\\\n",
    "                                      .replace('xe2x80x94', ' ').replace('xe2x80x99', \"'\")\\\n",
    "                                      .replace('xe2x80x98', \"'\").split())\n",
    "    return sample\n",
    "\n",
    "# clean newlines, carriage returns and tabs\n",
    "def clean_text(text):\n",
    "    cleaned_listed_text = []\n",
    "    listed_text = list(text)\n",
    "\n",
    "    for iter in range(len(listed_text) - 1):\n",
    "        if (listed_text[iter] == '\\\\' and listed_text[iter + 1] == 'n') or \\\n",
    "            (listed_text[iter] == 'n' and listed_text[iter - 1] == '\\\\'):\n",
    "            continue\n",
    "        elif listed_text[iter] == '\\\\' and listed_text[iter + 1] == 'r' or \\\n",
    "            (listed_text[iter] == 'r' and listed_text[iter - 1] == '\\\\'):\n",
    "            continue\n",
    "        elif listed_text[iter] == '\\\\' and listed_text[iter + 1] == 't' or \\\n",
    "            (listed_text[iter] == 't' and listed_text[iter - 1] == '\\\\'):\n",
    "            continue\n",
    "        elif listed_text[iter] == '\\\\':\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_listed_text.append(listed_text[iter])\n",
    "\n",
    "    cleaned_text = ''.join([str(char) for char in cleaned_listed_text])\n",
    "    cleaned_text = remove_funny_tokens(cleaned_text)\n",
    "\n",
    "    return ''.join(cleaned_text)\n",
    "\n",
    "df_metadata = pd.read_csv('gutenberg_metadata.csv')\n",
    "\n",
    "data = {'Author': None, 'Title': None, 'Link': None, 'ID': None, 'Bookshelf': None, 'Text': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d9ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754c1b9",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for key, row in df_metadata.iterrows():\n",
    "    print(x)\n",
    "    x += 1\n",
    "    if data['Author'] == None:\n",
    "        data['Author'] = [row['Author']]\n",
    "    else:\n",
    "        data['Author'].append(row['Author'])\n",
    "    if data['Title'] == None:\n",
    "        data['Title'] = [row['Title']]\n",
    "    else:\n",
    "        data['Title'].append(row['Title'])\n",
    "    \n",
    "    if data['Link'] == None:\n",
    "        data['Link'] = [row['Link']]\n",
    "    else:\n",
    "        data['Link'].append(row['Link'])\n",
    "    \n",
    "    book_id = int(row['Link'].split('/')[-1])\n",
    "\n",
    "    if data['ID'] == None:\n",
    "        data['ID'] = [book_id]\n",
    "    else:\n",
    "        data['ID'].append(book_id)\n",
    "    \n",
    "    if data['Bookshelf'] == None:\n",
    "        data['Bookshelf'] = [row['Bookshelf']]\n",
    "    else:\n",
    "        data['Bookshelf'].append(row['Bookshelf'])\n",
    "\n",
    "    text = np.nan\n",
    "    try:\n",
    "        text = strip_headers(load_etext(etextno=book_id, \n",
    "                                        mirror='http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/')).strip()\n",
    "        text = ' '.join(' '.join(' '.join(text.split('\\n')).split('\\t')).split('\\r'))\n",
    "        text = ' '.join(text.split())\n",
    "        text = clean_text(str(text))\n",
    "    except:\n",
    "        try: \n",
    "            page = requests.get(row['Link'])\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            text_link = 'http://www.gutenberg.org' + soup.find_all(\"a\", string=\"Plain Text UTF-8\")[0]['href']\n",
    "            http_response_object = urlopen(text_link)\n",
    "\n",
    "            text = strip_headers(str(http_response_object.read()))\n",
    "            text = ' '.join(' '.join(' '.join(text.split('\\n')).split('\\t')).split('\\r'))\n",
    "            text = ' '.join(text.split())\n",
    "            text = clean_text(str(text))\n",
    "        except:\n",
    "            print(\"Couldn't acquire text for \" + row['Title'] + ' with ID ' + str(book_id) + '. Link: ' + row['Link'])\n",
    "            \n",
    "    if data['Text'] == None:\n",
    "        data['Text'] = [' '.join(text.split(' '))]\n",
    "    else:\n",
    "        try:\n",
    "            data['Text'].append(' '.join(text.split(' ')))\n",
    "        except:\n",
    "            data['Text'].append(None)\n",
    "            print(\"Couldn't save data for \" + row['Title'] + ' with ID ' + str(book_id) + '. Link: ' + row['Link'])\n",
    "\n",
    "df_data = pd.DataFrame(data, columns = ['Title', 'Author', 'Link', 'ID', 'Bookshelf', 'Text'])\n",
    "\n",
    "df_data.to_csv('/content/gutenberg_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b853dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33128/18918058.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnameDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pg_catalog.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "nameDf = pd.read_csv(\"pg_catalog.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6141f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33128/1647065679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data' is not defined"
     ]
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da8e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
